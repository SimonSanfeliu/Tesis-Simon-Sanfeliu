{"Schema Linking": "\n    Given the user request, select the tables needed to generate a SQL query. \n    Give the answer in the following format: [table1, table2, ...]. For \n    example, if the answer is table object and table taxonomy, then you should \n    type: [object, taxonomy].\n    \n    User request: Give me all the SNe that were first detected between december first 2022 and september first 2023. Return the probability class, the last and the first detection date and the oids of the objects.\n    \n    ## Astronomical context:\n\n### Types of objects:\n- There are two main types of variable objects: those that have persistent variability and those that have a transient nature. \n- In the case of transient sources (Transient), the relevant light curve is the uncorrected magnitude (magpsf) and its error (sigmapsf).\n- In the case of persistent variability sources (Periodic or Stochastic), the relevant light curve magnitude is the corrected magnitude (magpsf_corr) and its error (sigmapsf_corr for periodic sources and sigmapsf_corr_ext for stochastic sources). \n\n### Definitions:\n- The initial rise rate is indicated by the dmdt_first column in the magstat table, separated by band. You need to use the filter id (fid) column to specify the given band.\n- If the user requests an initial rise rate greater than some value, what they mean is that the rise rate should be less than the negative of that value, because in astronomy magnitudes are lower for brighter objects, so when an object is rising its magnitudes are decreasing.\n- Objects that are transient are considered to be fast risers if dmdt_first < -0.25 mag per day (in the table magstat) in any band. \n\n### Restriction on dates or times:\n- When the user refers to the first detection of a given object, you should use the firstmjd column (indexed in the table object). \n- When possible, avoid adding restrictions on the mjd column in the detection table, try putting them in the object table instead.\n- All the rows in the detection table are by definition detections. this in not the case for the table forced_photometry, where even measurements that are not considered to be detections are reported. \n- You need to convert dates (if given) into mjd before doing any query.\n- If the year is not specified, assume that the user refers to the current year (2024).\n\n### Nested subqueries vs inner joins:\n- In general, if you need to query data from the detection and feature table, it is recommended to use nested subqueries that do the filtering with information not contained in the detection or feature table first, using the WHERE statement and requesting the oid column to be inside a given list. For example, use WHERE oid in {subquery}, where subquery returns a list of oids.\n- However, sometimes it is necessary to use an INNER JOIN between tables to get all the requested columns. When this happens, make sure to use the inner join clause when it is ABSOLUTELY necessary.\n\n### Samples of objects:\n- If you are asked to provide a sample of a given set of objects, you can use the LIMIT command. If you do this, it will be more feasible to do multiple inner joins in some cases.\n- When you are asked to find 'at most' a number of examples, use the 'LIMIT {n}' command in SQL, where n is the number of examples.\n\n### Object table:\n- The number of detections is contained in the ndet variable located in the object table.\n\n### Probability table:\n- Use the ranking=1 column in the probability table to get the highest probability class (for a given classifier and classifier_version).\n- The probability table has the column \"classifier_version\", that indicates the version of the classifier used. Use this column to specifiy the version of the classifier for the particular query.\n- If you are querying the probability table to get a list of oids, and if you want to get only one result for a given classifier, irrespective of the version of the classifier, use the DISTINCT command, e.g. 'SELECT DISTINCT oid'. However, it is preferable that the version of the classifier is specified. \n- If you want to check that an object is periodic, you could check whether the probability of being in the periodic branch (lc_classifier_periodic) has the largest value (ranking=1).\n- Keep in mind that sometimes the concept of probability is referred to as a \"posibility\" by some users.\n\n### feature table\n- You should avoid using the feature table as much as possible, since it is generally very expensive to query data from it.\n- For example, avoid using the feature (or detection) table to get the time of first detection, use the firstmjd column from the object table instead.\n- If you do want to select objects based on restrictions on the feature table, we recommend that you use nested subqueries, where the innermost query defines the sample based on restrictions in the feature or other tables, and where the \nupper levels do inner joins between the different tables and select the necessary columns. \n- The galactic latitude is in the value column of the feature table, for name='gal_b'.\n- The difference between the minimum and maximum magnitudes in ZTF for a given band is in the value column of the feature table, for name='delta_mag_fid'.\n- The light curve (photometric) period is in the value column of the feature table, for name='Multiband_period'.\n- The light curve amplitude is in the value column of the feature table, for name='Amplitude'.\n\n### detection table:\n- Every detection in the detection table has a unique candidate identifier (indexed column candid)\n- When asked for magnitude errors, the user is referring to the columns sigmapsf_corr and sigmapsf_corr_ext from the detection table.\n\n### dataquality table:\n- The dataquality table contains information related to the quality of every detection in the database. It has information for every object (with index oid) and candidate detection (with index candid) that is not available in the detection table. \n- Some of the most relevant columns are the reduced chi-square for PSF-fit (chipsf), the full width half maximum (fwhm), the star galaxy \nclassification score from SEXtractor (classtar), and the magnitude zero point estimate and its error (magzpsci, magzpunc).\n\n### forced_photometry table:\n- the forced photometry tables contains light curve measurements for all detected objects even when they didn't trigger a detection, but only from December 2023. \n\n### non_detection table:\n- the non detection table contains upper limits for the absolute difference with respect to the reference when no detections were triggered in objects that have associated alerts. \n\n### PanSTARRS (PS1) and the ps1_ztf table:\n- The ps1_ztf table contains information about the closest sources in the PanSTARRS catalog. \n- Variables ending in 1 refer to the closest object, variables ending in 2 refer to the second closest object, and variables ending in 3 refer to third closest object. For example, the variables associated to these closest PS1 objects from a given ZTF object are sgscore1, which is the star galaxy classication score; distpsnr1, which is the distance to the source; sgmag1, srmag1, simag1, szmag1 which are \nthe magnitudes in the g, r, i, and z bands, respectively; and objectidps1, which is the PanSTARRS unique identifier of the object.\n\n### gaia_ztf:\n- Objects have information about the nearest objects in the Gaia catalog in the gaia_ztf table.\n- The key quantities are the distance to the closest gaia source irrespective of magnitude (neargaia) and the magnitude of the closest source (maggaia). \n\n### ss_ztf:\n- Objects that have Solar System counterparts (asteroids or moving objects) have this information stored in the ss_ztf table.\n- The key quantities for a given oid and candid are the distance to the nearest known Solar System object in arcsec (ssdistnr), its magnitude (ssmagnr), and its name (ssnamenr).\n\n### allwise table:\n- We keep a copy of the allwise catalog objects that are found when crossmatching ZTF objects against Allwise in the allwise table.\n- The key quantities are the name of the object in the allwise catalog (oid_catalog), its right ascension and declination (ra and dec), and the W1 to W4 magnitudes (w1mpro to w4mpro) and errors (w1sigmpro to w4sigmpro) \n\n### xmatch table:\n- The xmatch table has three identifiers that are indexed columns: oid, which corresponds to the unique ZTF identifier; catid, which corresponds to the catalog identifier; and oid_catalog, which is the unique identifier for a given source in the catalog nomenclature. \n- If you want to associate objects in xmatch with one of the available xmatch catalogs, e.g. allwise, you should first do an inner join between xmatch and allwise using the oid_catalog identifier. \n- If you want to restrict the query to some objects based on other properties, you should use two nested queries that first select the oid_catalog identifiers and a second innermost query that uses the oid column to apply additional restrictions, e.g.\n```python\ninnermostquery = '''\nSELECT\n    oid\nFROM\n    object\nWHERE\n    ndet>1\n'''\nsubquery = '''\nSELECT\n   oid_catalog\nFROM\n   xmatch\nWHERE\n   oid IN {innermostquery}\n'''\nfinal_query = '''\nSELECT\n   *\nFROM\n   xmatch INNER JOIN allwise\n   ON xmatch.oid_catalog=allwise.oid_catalog\nWHERE\n   allwise.oid_catalog IN {subquery}\n'''\n```\n\n### Spatial queries: \nTo look for matches between the object table and a set of coordinates given a crossmatch radius, you can use the q3c_join function as shown below:\n```python\n# Prepare the query\nquery = '''\n-- ids and coordinates of the catalog against which we want to crossmatch\nWITH catalog ( source_id, ra, dec) AS (\n    VALUES\n        {values}\n)\nSELECT \n    c.source_id, c.ra, c.dec, o.oid, o.meanra, o.meandec, q3c_dist(c.ra,c.dec,o.meanra,o.meandec), \n    o.firstmjd\n\nFROM object o, catalog c\n    -- It is REALLY important to first use the catalog then the object ra,dec for speed. The radius is in degrees.\nWHERE\n    q3c_join(c.ra, c.dec, o.meanra, o.meandec, {radius})\n'''\n```\nIn this example, we also return the distance between matching objects \nusing the q3c_dist function, as well as other properties from the object table. \nIt is very important that the radius variable should be in degrees. In this example, the values variable should \ncorrespond to the list of coordinates using the following format, e.g. \n'(id1,ra1,dec1),\\n(id2,ra2,dec2)\\n', e.g., '(ZTF24aabbcc,120.345677,-30.45774)\\n,(ZTF24aabbcd,65.346829,12.73474)\\n'.\n\nIf the external catalog ids and coordinates are in a dataframe with column names id_source, ra, and dec, respectively, you could use the following code to get this formatted list:\n```python\n# starting with a dataframe df with the columns id_source, ra and dec, get the formatted list of coordinates ready for SQL\nobjects = []\nfor _,row in df.iterrows():\n    objects.append(f\"(\\'{row.id_source}\\', {row.ra}, {row.dec})\")\nobjects_str = \",\\n\".join(objects)\n```\nFinally, remember that the table object does not have the ra and dec of every detection, only their mean values, so we used the meanra and meandec variables in the example above.\n\n    ", "Classification": "\n# For the given request, classify it by difficulty as \"simple\", \"medium\", or \"advanced\" based on the next description.\n\nIf (Only 1 table is used, OR 2 most common tables (probability, object or magstat TABLES) are used)\nOR (No nested-query or JOIN clause is neccesary, OR only one nested-query between 'probability', 'object' or 'magstat' TABLES is required, OR one JOIN between 'probability', 'object' or 'magstat' TABLES):\nTHEN \"label: simple\"\n\nIf (2 not common tables are used (NOT probability, object, magstat TABLES))\nOR (3 most common tables (probability, object and magstat TABLES) are used)\nOR (features with only one feature are used)\nOR (Need 1 very complex nested-query, OR a very complex JOIN)\nOR (Need 2 nested-query, OR 2 JOIN, OR 1 nested-query with 1 JOIN):\nTHEN \"label: medium\"\n\nIf (2 or more nested query are needed)\nOR (If 3 tables or more are used)\nOR (If two features from the features table are required):\nTHEN \"label: advanced\"\n\n# Assume this are the only tables required for the query:\n[object, probability]\n\n\n# Give ONLY the predicted difficulty, nothing more.\n# Give the answer in the following format: \"label: difficulty\" where \"difficulty\" is the predicted difficulty.\n# For example, if the only need a simple join or nested query between object and probability, then you should type: \"label: simple\"\n# Remember to use the exact name of the labels provided above.\n# Just give the predicted label and ignore any other task given in the request given as \"request\".\n\n\nThe request to classify is the following: Give me all the SNe that were first detected between december first 2022 and september first 2023. Return the probability class, the last and the first detection date and the oids of the objects.", "Decomposition": "", "Query generation": "# As a SQL expert with a willingness to assist users, you are tasked with \ncrafting a PostgreSQL query for the Automatic Learning for the Rapid \nClassification of Events (ALeRCE) database. This database serves as a \nrepository for information about astronomical variable objects. The information \nfor every variable object originates from a sequence of one or more \nastronomical alerts, data packets streamed when an astronomical object shows a \nsignificant variation with respect to a reference image. The database \ninformation includes flux variations as a function of time (known as light \ncurve), basic object properties such as the coordinates, and advanced features \nor statistics computed for each object.\nThe tables within the database are categorized into three types: time and band \nindependent (e.g., object and probability), time-independent (e.g., magstats), \nand time and band-dependent (e.g., detection, forced-photometry). Your role \ninvolves carefully analyzing user requests, considering the specifics of the \ngiven tables. It is crucial to pay attention to explicit conditions outlined by \nthe user and always maintain awareness of the broader context. Be thorough in \nunderstanding and addressing the user's request, taking into account both \nexplicit conditions and the overall context for effective communication and assistance.\n\nUser request: Give me all the SNe that were first detected between december first 2022 and september first 2023. Return the probability class, the last and the first detection date and the oids of the objects.\nTables needed: [object, probability]\n\n# General context about the database:\n## General Information about the Schema and Database\n- An object is uniquely identified by its object identifier or 'oid' index, \nused in most tables\n- A detection from an object is identified by the candidate identifier or \n'candid' index, used only in the detection table\n- A given band is identified by the filter identifier or 'fid' index, used in \nthe magstats, feature, and detection tables\n- In most cases you will need to use information from the object table\n- When particular astronomical classes are requested, you will need to use the \nprobability table \n- Prioritize obtaining oids in a subquery to optimize the main query.\n- Utilize nested queries to retrieve oids, preferably selecting the \n'probability' or 'object' table.\n- Avoid JOIN clauses; instead, favor nested queries.\n- Beware of variables that are not indexed when doing the queries. Favour using \nnested queries where the inner queries use indexed variables.\n- Note that the typical timeout time is 2 minutes\n- Special attention needs to be paid to the feature table, which, if possible, \nshould be avoided. In this table the name of a given feature is stored in the \ncolumn 'name' and its value for a given object in the column 'value'. These \ncolumns are not indexed, so you should query this table in the outer levels of \na nested query, after most of the filtering has already happened using indexed \nvariables.\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \"\"stamp_classifier\"\"): A convolutional neural \n  network that uses as input the image stamps from a given object and that uses \n  a 5 class taxonomy. This classifier is triggered only by the first alert of \n  every object.\n- Light Curve Classifier (denoted as \"\"lc_classifier\"\"): A balanced \n  hierarchical random forest classifier that uses as input object features and \n  that consists of four models with a taxonomy of 15 classes in total. This \n  classifier is triggered with every new alert of an object with at least six \n  detections in a given band.\n- The first hierarchical classifier of the Light Curve Classifier has three \n  classes: [periodic, stochastic, transient], denoted as \"\"lc_classifier_top.\"\"\n- Three additional classifiers of the Light Curve Classifier specialize in \n  different types of object: Periodic, Transient, and Stochastic, denoted as \n  \"\"lc_classifier_periodic,\"\" \"\"lc_classifier_transient,\"\" and \n  \"\"lc_classifier_stochastic,\"\" respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super \n    Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), \n    'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object \n    ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('Ceph'), Long \n    Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects \n    ('Periodic-Other')].\n## Probability Variable Names\n- classifier_name=('lc_classifier', 'lc_classifier_top', \n  'lc_classifier_transient', 'lc_classifier_stochastic', \n  'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', \n  'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('transient', 'stochastic', 'periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\n## Astronomical context:\n\n### Types of objects:\n- There are two main types of variable objects: those that have persistent variability and those that have a transient nature. \n- In the case of transient sources (Transient), the relevant light curve is the uncorrected magnitude (magpsf) and its error (sigmapsf).\n- In the case of persistent variability sources (Periodic or Stochastic), the relevant light curve magnitude is the corrected magnitude (magpsf_corr) and its error (sigmapsf_corr for periodic sources and sigmapsf_corr_ext for stochastic sources). \n\n### Definitions:\n- The initial rise rate is indicated by the dmdt_first column in the magstat table, separated by band. You need to use the filter id (fid) column to specify the given band.\n- If the user requests an initial rise rate greater than some value, what they mean is that the rise rate should be less than the negative of that value, because in astronomy magnitudes are lower for brighter objects, so when an object is rising its magnitudes are decreasing.\n- Objects that are transient are considered to be fast risers if dmdt_first < -0.25 mag per day (in the table magstat) in any band. \n\n### Restriction on dates or times:\n- When the user refers to the first detection of a given object, you should use the firstmjd column (indexed in the table object). \n- When possible, avoid adding restrictions on the mjd column in the detection table, try putting them in the object table instead.\n- All the rows in the detection table are by definition detections. this in not the case for the table forced_photometry, where even measurements that are not considered to be detections are reported. \n- You need to convert dates (if given) into mjd before doing any query.\n- If the year is not specified, assume that the user refers to the current year (2024).\n\n### Nested subqueries vs inner joins:\n- In general, if you need to query data from the detection and feature table, it is recommended to use nested subqueries that do the filtering with information not contained in the detection or feature table first, using the WHERE statement and requesting the oid column to be inside a given list. For example, use WHERE oid in {subquery}, where subquery returns a list of oids.\n- However, sometimes it is necessary to use an INNER JOIN between tables to get all the requested columns. When this happens, make sure to use the inner join clause when it is ABSOLUTELY necessary.\n\n### Samples of objects:\n- If you are asked to provide a sample of a given set of objects, you can use the LIMIT command. If you do this, it will be more feasible to do multiple inner joins in some cases.\n- When you are asked to find 'at most' a number of examples, use the 'LIMIT {n}' command in SQL, where n is the number of examples.\n\n### Object table:\n- The number of detections is contained in the ndet variable located in the object table.\n\n### Probability table:\n- Use the ranking=1 column in the probability table to get the highest probability class (for a given classifier and classifier_version).\n- The probability table has the column \"classifier_version\", that indicates the version of the classifier used. Use this column to specifiy the version of the classifier for the particular query.\n- If you are querying the probability table to get a list of oids, and if you want to get only one result for a given classifier, irrespective of the version of the classifier, use the DISTINCT command, e.g. 'SELECT DISTINCT oid'. However, it is preferable that the version of the classifier is specified. \n- If you want to check that an object is periodic, you could check whether the probability of being in the periodic branch (lc_classifier_periodic) has the largest value (ranking=1).\n- Keep in mind that sometimes the concept of probability is referred to as a \"posibility\" by some users.\n\n### feature table\n- You should avoid using the feature table as much as possible, since it is generally very expensive to query data from it.\n- For example, avoid using the feature (or detection) table to get the time of first detection, use the firstmjd column from the object table instead.\n- If you do want to select objects based on restrictions on the feature table, we recommend that you use nested subqueries, where the innermost query defines the sample based on restrictions in the feature or other tables, and where the \nupper levels do inner joins between the different tables and select the necessary columns. \n- The galactic latitude is in the value column of the feature table, for name='gal_b'.\n- The difference between the minimum and maximum magnitudes in ZTF for a given band is in the value column of the feature table, for name='delta_mag_fid'.\n- The light curve (photometric) period is in the value column of the feature table, for name='Multiband_period'.\n- The light curve amplitude is in the value column of the feature table, for name='Amplitude'.\n\n### detection table:\n- Every detection in the detection table has a unique candidate identifier (indexed column candid)\n- When asked for magnitude errors, the user is referring to the columns sigmapsf_corr and sigmapsf_corr_ext from the detection table.\n\n### dataquality table:\n- The dataquality table contains information related to the quality of every detection in the database. It has information for every object (with index oid) and candidate detection (with index candid) that is not available in the detection table. \n- Some of the most relevant columns are the reduced chi-square for PSF-fit (chipsf), the full width half maximum (fwhm), the star galaxy \nclassification score from SEXtractor (classtar), and the magnitude zero point estimate and its error (magzpsci, magzpunc).\n\n### forced_photometry table:\n- the forced photometry tables contains light curve measurements for all detected objects even when they didn't trigger a detection, but only from December 2023. \n\n### non_detection table:\n- the non detection table contains upper limits for the absolute difference with respect to the reference when no detections were triggered in objects that have associated alerts. \n\n### PanSTARRS (PS1) and the ps1_ztf table:\n- The ps1_ztf table contains information about the closest sources in the PanSTARRS catalog. \n- Variables ending in 1 refer to the closest object, variables ending in 2 refer to the second closest object, and variables ending in 3 refer to third closest object. For example, the variables associated to these closest PS1 objects from a given ZTF object are sgscore1, which is the star galaxy classication score; distpsnr1, which is the distance to the source; sgmag1, srmag1, simag1, szmag1 which are \nthe magnitudes in the g, r, i, and z bands, respectively; and objectidps1, which is the PanSTARRS unique identifier of the object.\n\n### gaia_ztf:\n- Objects have information about the nearest objects in the Gaia catalog in the gaia_ztf table.\n- The key quantities are the distance to the closest gaia source irrespective of magnitude (neargaia) and the magnitude of the closest source (maggaia). \n\n### ss_ztf:\n- Objects that have Solar System counterparts (asteroids or moving objects) have this information stored in the ss_ztf table.\n- The key quantities for a given oid and candid are the distance to the nearest known Solar System object in arcsec (ssdistnr), its magnitude (ssmagnr), and its name (ssnamenr).\n\n### allwise table:\n- We keep a copy of the allwise catalog objects that are found when crossmatching ZTF objects against Allwise in the allwise table.\n- The key quantities are the name of the object in the allwise catalog (oid_catalog), its right ascension and declination (ra and dec), and the W1 to W4 magnitudes (w1mpro to w4mpro) and errors (w1sigmpro to w4sigmpro) \n\n### xmatch table:\n- The xmatch table has three identifiers that are indexed columns: oid, which corresponds to the unique ZTF identifier; catid, which corresponds to the catalog identifier; and oid_catalog, which is the unique identifier for a given source in the catalog nomenclature. \n- If you want to associate objects in xmatch with one of the available xmatch catalogs, e.g. allwise, you should first do an inner join between xmatch and allwise using the oid_catalog identifier. \n- If you want to restrict the query to some objects based on other properties, you should use two nested queries that first select the oid_catalog identifiers and a second innermost query that uses the oid column to apply additional restrictions, e.g.\n```python\ninnermostquery = '''\nSELECT\n    oid\nFROM\n    object\nWHERE\n    ndet>1\n'''\nsubquery = '''\nSELECT\n   oid_catalog\nFROM\n   xmatch\nWHERE\n   oid IN {innermostquery}\n'''\nfinal_query = '''\nSELECT\n   *\nFROM\n   xmatch INNER JOIN allwise\n   ON xmatch.oid_catalog=allwise.oid_catalog\nWHERE\n   allwise.oid_catalog IN {subquery}\n'''\n```\n\n### Spatial queries: \nTo look for matches between the object table and a set of coordinates given a crossmatch radius, you can use the q3c_join function as shown below:\n```python\n# Prepare the query\nquery = '''\n-- ids and coordinates of the catalog against which we want to crossmatch\nWITH catalog ( source_id, ra, dec) AS (\n    VALUES\n        {values}\n)\nSELECT \n    c.source_id, c.ra, c.dec, o.oid, o.meanra, o.meandec, q3c_dist(c.ra,c.dec,o.meanra,o.meandec), \n    o.firstmjd\n\nFROM object o, catalog c\n    -- It is REALLY important to first use the catalog then the object ra,dec for speed. The radius is in degrees.\nWHERE\n    q3c_join(c.ra, c.dec, o.meanra, o.meandec, {radius})\n'''\n```\nIn this example, we also return the distance between matching objects \nusing the q3c_dist function, as well as other properties from the object table. \nIt is very important that the radius variable should be in degrees. In this example, the values variable should \ncorrespond to the list of coordinates using the following format, e.g. \n'(id1,ra1,dec1),\\n(id2,ra2,dec2)\\n', e.g., '(ZTF24aabbcc,120.345677,-30.45774)\\n,(ZTF24aabbcd,65.346829,12.73474)\\n'.\n\nIf the external catalog ids and coordinates are in a dataframe with column names id_source, ra, and dec, respectively, you could use the following code to get this formatted list:\n```python\n# starting with a dataframe df with the columns id_source, ra and dec, get the formatted list of coordinates ready for SQL\nobjects = []\nfor _,row in df.iterrows():\n    objects.append(f\"(\\'{row.id_source}\\', {row.ra}, {row.dec})\")\nobjects_str = \",\\n\".join(objects)\n```\nFinally, remember that the table object does not have the ra and dec of every detection, only their mean values, so we used the meanra and meandec variables in the example above.\n\n\n## Important details about the database required for the query:\n## Default Parameters to Consider\n- Class probabilities for a given classifier and object are sorted from most to \n  least likely, where the relative position is indicated by the 'ranking' \n  column in the probability table. Hence, the most probable class should have 'ranking'=1.\n- The ALeRCE classification pipeline includes a Stamp Classifier and a Light \n  Curve Classifier. The Light Curve classifier employs a hierarchical \n  classification. If no classifier is specified, use \n  'classifier_name=\"\"lc_classifier\"\"' when selecting probabilities.\n- If the user doesn't specify explicit columns, use the \"SELECT\" SQL statement \nto choose all possible columns.\n- Avoid changing the names of columns or tables unless necessary for the SQL query.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# Answer ONLY with a SQL query, with the following format: \n```sql SQL_QUERY_HERE ```\n\nDON'T include anything else in your answer.", "Self-correction": "\nAs a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nThe user values the personality of a knowledgeable SQL expert, so ensuring accuracy is paramount. Be thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as 'stamp_classifier'): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as 'lc_classifier'): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [periodic, stochastic, transient], denoted as 'lc_classifier_top.'\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as 'lc_classifier_periodic,' 'lc_classifier_transient,' and 'lc_classifier_stochastic,' respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('Ceph'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('transient', 'stochastic', 'periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \"SELECT *\" SQL statement.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n# If you need to use 2 or 3 tables, try using a sub-query over 'probability' or 'object' if it is necessary (priority in this order).\n\n## Astronomical context:\n\n### Types of objects:\n- There are two main types of variable objects: those that have persistent variability and those that have a transient nature. \n- In the case of transient sources (Transient), the relevant light curve is the uncorrected magnitude (magpsf) and its error (sigmapsf).\n- In the case of persistent variability sources (Periodic or Stochastic), the relevant light curve magnitude is the corrected magnitude (magpsf_corr) and its error (sigmapsf_corr for periodic sources and sigmapsf_corr_ext for stochastic sources). \n\n### Definitions:\n- The initial rise rate is indicated by the dmdt_first column in the magstat table, separated by band. You need to use the filter id (fid) column to specify the given band.\n- If the user requests an initial rise rate greater than some value, what they mean is that the rise rate should be less than the negative of that value, because in astronomy magnitudes are lower for brighter objects, so when an object is rising its magnitudes are decreasing.\n- Objects that are transient are considered to be fast risers if dmdt_first < -0.25 mag per day (in the table magstat) in any band. \n\n### Restriction on dates or times:\n- When the user refers to the first detection of a given object, you should use the firstmjd column (indexed in the table object). \n- When possible, avoid adding restrictions on the mjd column in the detection table, try putting them in the object table instead.\n- All the rows in the detection table are by definition detections. this in not the case for the table forced_photometry, where even measurements that are not considered to be detections are reported. \n- You need to convert dates (if given) into mjd before doing any query.\n- If the year is not specified, assume that the user refers to the current year (2024).\n\n### Nested subqueries vs inner joins:\n- In general, if you need to query data from the detection and feature table, it is recommended to use nested subqueries that do the filtering with information not contained in the detection or feature table first, using the WHERE statement and requesting the oid column to be inside a given list. For example, use WHERE oid in {subquery}, where subquery returns a list of oids.\n- However, sometimes it is necessary to use an INNER JOIN between tables to get all the requested columns. When this happens, make sure to use the inner join clause when it is ABSOLUTELY necessary.\n\n### Samples of objects:\n- If you are asked to provide a sample of a given set of objects, you can use the LIMIT command. If you do this, it will be more feasible to do multiple inner joins in some cases.\n- When you are asked to find 'at most' a number of examples, use the 'LIMIT {n}' command in SQL, where n is the number of examples.\n\n### Object table:\n- The number of detections is contained in the ndet variable located in the object table.\n\n### Probability table:\n- Use the ranking=1 column in the probability table to get the highest probability class (for a given classifier and classifier_version).\n- The probability table has the column \"classifier_version\", that indicates the version of the classifier used. Use this column to specifiy the version of the classifier for the particular query.\n- If you are querying the probability table to get a list of oids, and if you want to get only one result for a given classifier, irrespective of the version of the classifier, use the DISTINCT command, e.g. 'SELECT DISTINCT oid'. However, it is preferable that the version of the classifier is specified. \n- If you want to check that an object is periodic, you could check whether the probability of being in the periodic branch (lc_classifier_periodic) has the largest value (ranking=1).\n- Keep in mind that sometimes the concept of probability is referred to as a \"posibility\" by some users.\n\n### feature table\n- You should avoid using the feature table as much as possible, since it is generally very expensive to query data from it.\n- For example, avoid using the feature (or detection) table to get the time of first detection, use the firstmjd column from the object table instead.\n- If you do want to select objects based on restrictions on the feature table, we recommend that you use nested subqueries, where the innermost query defines the sample based on restrictions in the feature or other tables, and where the \nupper levels do inner joins between the different tables and select the necessary columns. \n- The galactic latitude is in the value column of the feature table, for name='gal_b'.\n- The difference between the minimum and maximum magnitudes in ZTF for a given band is in the value column of the feature table, for name='delta_mag_fid'.\n- The light curve (photometric) period is in the value column of the feature table, for name='Multiband_period'.\n- The light curve amplitude is in the value column of the feature table, for name='Amplitude'.\n\n### detection table:\n- Every detection in the detection table has a unique candidate identifier (indexed column candid)\n- When asked for magnitude errors, the user is referring to the columns sigmapsf_corr and sigmapsf_corr_ext from the detection table.\n\n### dataquality table:\n- The dataquality table contains information related to the quality of every detection in the database. It has information for every object (with index oid) and candidate detection (with index candid) that is not available in the detection table. \n- Some of the most relevant columns are the reduced chi-square for PSF-fit (chipsf), the full width half maximum (fwhm), the star galaxy \nclassification score from SEXtractor (classtar), and the magnitude zero point estimate and its error (magzpsci, magzpunc).\n\n### forced_photometry table:\n- the forced photometry tables contains light curve measurements for all detected objects even when they didn't trigger a detection, but only from December 2023. \n\n### non_detection table:\n- the non detection table contains upper limits for the absolute difference with respect to the reference when no detections were triggered in objects that have associated alerts. \n\n### PanSTARRS (PS1) and the ps1_ztf table:\n- The ps1_ztf table contains information about the closest sources in the PanSTARRS catalog. \n- Variables ending in 1 refer to the closest object, variables ending in 2 refer to the second closest object, and variables ending in 3 refer to third closest object. For example, the variables associated to these closest PS1 objects from a given ZTF object are sgscore1, which is the star galaxy classication score; distpsnr1, which is the distance to the source; sgmag1, srmag1, simag1, szmag1 which are \nthe magnitudes in the g, r, i, and z bands, respectively; and objectidps1, which is the PanSTARRS unique identifier of the object.\n\n### gaia_ztf:\n- Objects have information about the nearest objects in the Gaia catalog in the gaia_ztf table.\n- The key quantities are the distance to the closest gaia source irrespective of magnitude (neargaia) and the magnitude of the closest source (maggaia). \n\n### ss_ztf:\n- Objects that have Solar System counterparts (asteroids or moving objects) have this information stored in the ss_ztf table.\n- The key quantities for a given oid and candid are the distance to the nearest known Solar System object in arcsec (ssdistnr), its magnitude (ssmagnr), and its name (ssnamenr).\n\n### allwise table:\n- We keep a copy of the allwise catalog objects that are found when crossmatching ZTF objects against Allwise in the allwise table.\n- The key quantities are the name of the object in the allwise catalog (oid_catalog), its right ascension and declination (ra and dec), and the W1 to W4 magnitudes (w1mpro to w4mpro) and errors (w1sigmpro to w4sigmpro) \n\n### xmatch table:\n- The xmatch table has three identifiers that are indexed columns: oid, which corresponds to the unique ZTF identifier; catid, which corresponds to the catalog identifier; and oid_catalog, which is the unique identifier for a given source in the catalog nomenclature. \n- If you want to associate objects in xmatch with one of the available xmatch catalogs, e.g. allwise, you should first do an inner join between xmatch and allwise using the oid_catalog identifier. \n- If you want to restrict the query to some objects based on other properties, you should use two nested queries that first select the oid_catalog identifiers and a second innermost query that uses the oid column to apply additional restrictions, e.g.\n```python\ninnermostquery = '''\nSELECT\n    oid\nFROM\n    object\nWHERE\n    ndet>1\n'''\nsubquery = '''\nSELECT\n   oid_catalog\nFROM\n   xmatch\nWHERE\n   oid IN {innermostquery}\n'''\nfinal_query = '''\nSELECT\n   *\nFROM\n   xmatch INNER JOIN allwise\n   ON xmatch.oid_catalog=allwise.oid_catalog\nWHERE\n   allwise.oid_catalog IN {subquery}\n'''\n```\n\n### Spatial queries: \nTo look for matches between the object table and a set of coordinates given a crossmatch radius, you can use the q3c_join function as shown below:\n```python\n# Prepare the query\nquery = '''\n-- ids and coordinates of the catalog against which we want to crossmatch\nWITH catalog ( source_id, ra, dec) AS (\n    VALUES\n        {values}\n)\nSELECT \n    c.source_id, c.ra, c.dec, o.oid, o.meanra, o.meandec, q3c_dist(c.ra,c.dec,o.meanra,o.meandec), \n    o.firstmjd\n\nFROM object o, catalog c\n    -- It is REALLY important to first use the catalog then the object ra,dec for speed. The radius is in degrees.\nWHERE\n    q3c_join(c.ra, c.dec, o.meanra, o.meandec, {radius})\n'''\n```\nIn this example, we also return the distance between matching objects \nusing the q3c_dist function, as well as other properties from the object table. \nIt is very important that the radius variable should be in degrees. In this example, the values variable should \ncorrespond to the list of coordinates using the following format, e.g. \n'(id1,ra1,dec1),\\n(id2,ra2,dec2)\\n', e.g., '(ZTF24aabbcc,120.345677,-30.45774)\\n,(ZTF24aabbcd,65.346829,12.73474)\\n'.\n\nIf the external catalog ids and coordinates are in a dataframe with column names id_source, ra, and dec, respectively, you could use the following code to get this formatted list:\n```python\n# starting with a dataframe df with the columns id_source, ra and dec, get the formatted list of coordinates ready for SQL\nobjects = []\nfor _,row in df.iterrows():\n    objects.append(f\"(\\'{row.id_source}\\', {row.ra}, {row.dec})\")\nobjects_str = \",\\n\".join(objects)\n```\nFinally, remember that the table object does not have the ra and dec of every detection, only their mean values, so we used the meanra and meandec variables in the example above.\n\n\n# Generate a query for each step, resolving and analysing it, with the following format:\n```python sub_queries = [VARIABLE SUB-QUERY HERE] ```\n# Finally, join all the steps in a final query like so: \n```python full_query = [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer. Remember to always add the f in the string of the final query to add up all the sub-queries\n\n\n# Correct a SQL query given the next user request:\nGive me all the SNe that were first detected between december first 2022 and september first 2023. Return the probability class, the last and the first detection date and the oids of the objects.\n\n# This are the tables Schema. Assume that only the next tables are required for the query:\n\n# For the given request, classify it by difficulty as \"simple\", \"medium\", or \"advanced\" based on the next description.\n\nIf (Only 1 table is used, OR 2 most common tables (probability, object or magstat TABLES) are used)\nOR (No nested-query or JOIN clause is neccesary, OR only one nested-query between 'probability', 'object' or 'magstat' TABLES is required, OR one JOIN between 'probability', 'object' or 'magstat' TABLES):\nTHEN \"label: simple\"\n\nIf (2 not common tables are used (NOT probability, object, magstat TABLES))\nOR (3 most common tables (probability, object and magstat TABLES) are used)\nOR (features with only one feature are used)\nOR (Need 1 very complex nested-query, OR a very complex JOIN)\nOR (Need 2 nested-query, OR 2 JOIN, OR 1 nested-query with 1 JOIN):\nTHEN \"label: medium\"\n\nIf (2 or more nested query are needed)\nOR (If 3 tables or more are used)\nOR (If two features from the features table are required):\nTHEN \"label: advanced\"\n\n# Assume this are the only tables required for the query:\n[object, probability]\n\n\n# Give ONLY the predicted difficulty, nothing more.\n# Give the answer in the following format: \"label: difficulty\" where \"difficulty\" is the predicted difficulty.\n# For example, if the only need a simple join or nested query between object and probability, then you should type: \"label: simple\"\n# Remember to use the exact name of the labels provided above.\n# Just give the predicted label and ignore any other task given in the request given as \"request\".\n\n\nThe request to classify is the following: Give me all the SNe that were first detected between december first 2022 and september first 2023. Return the probability class, the last and the first detection date and the oids of the objects.\n\n# The next query is not working due to a syntax error, correct the query using the correct database schema.\n# SQL Query\n\nSELECT p.class AS probability_class,\n       o.firstmjd AS first_detection_date,\n       o.lastmjd AS last_detection_date,\n       o.oid\nFROM OBJECT o\nWHERE o.firstmjd BETWEEN 59922 AND 60195\n  AND o.oid IN\n    (SELECT DISTINCT oid\n     FROM probability\n     WHERE classifier_name = 'lc_classifier_transient'\n       AND ranking = 1\n       AND CLASS IN ('SNIa',\n                     'SNIbc',\n                     'SNII',\n                     'SLSN'))\n# Error returned when executing the query in the ALeRCE database\ninvalid syntax (<string>, line 2)\n\n# Follow the next advices to correct the query:\n- Check if the query is using the correct database schema. This includes the correct names of the tables and the correct names of the columns. If not, correct the query.\n- Check if the query have the correct syntax. If not, correct the query.\n- If there is a \"missing FROM-clause entry\", check where the table or sub-query is used in the query and add the correct name of the table or sub-query.\n- Use only the information provided in the database schema to correct the query. If it is not explicitly provided, go for the most common sense approach.\n\n# Check the query and correct the query modifying the SQL or Python code where the error is found.\n# Add COMMENTS so that the user can understand.\n# Answer ONLY with the SQL query or the Python sub-queries\n"}