{'Schema Linking': "\n    Given the user request, select the tables needed to generate a SQL query. \n    Give the answer in the following format: [table1, table2, ...]. For \n    example, if the answer is table object and table taxonomy, then you should \n    type: [object, taxonomy].\n    \n    User request: Get the object identifier, candidate identifier, psf magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag.\n    \n    ## Astronomical context:\n    There are two main types of variable objects: those that have persistent \n    variability and those that have a transient nature. In the case of \n    persistent variability sources (Periodic or Stochastic), the relevant light \n    curve magnitude is the corrected magnitude (magpsf_corr). In the case of \n    transient sources (Transient), the relevant light curve is the uncorrected \n    magnitude (magpsf). Objects that are transient are considered to be fast \n    risers if dmd_dt < -0.25 mag per day (in magstats) in any band. Note that \n    when the user refers to the first detection of a given object, you should \n    use the firstmjd indexed column (in object). When possible, avoid adding \n    restrictions on the mjd column in the detection table, try putting them in \n    the object table first. Note that all the rows in the detection table are \n    by definition detections, you don't need to ask for additional constraints.\n    ", 'Classification': 'Get the object identifier, candidate identifier, psf magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag.\n The following tables are needed to generate \n    the query: [object, detection, magstat]', 'Decomposition': '# Your task is to DECOMPOSE the user request into a series of steps required to \ngenerate a PostgreSQL query that will be used for retrieving requested \ninformation from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, \ndescribing and breaking down the problem into subtasks and/or subqueries.\nBe careful to put all the information and details needed in the description, \nlike conditions, the table and column names, etc.\nTake in consideration the advices, conditions and names from \n""General Context"" and details of the database, or the query will not be \noptimal. List the steps in the order in which they should be planned. Add to \neach numbered step a label in square brackets, like [initial planning], [join \ntable], [replace], [condition], [join], [sub-query], etc.\nThe request is a very difficult and advanced query, so you will need to use \nJOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is \nvery important that you give every possible detail in each step, describing the \nstatements and the nested-queries that are required.\n\nUser request: Get the object identifier, candidate identifier, psf magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag.\nTables needed: [object, detection, magstat]\n\n# General context about the database:\n## General Information about the Schema and Database\n- An object is uniquely identified by its object identifier or \'oid\' index, \nused in most tables\n- A detection from an object is identified by the candidate identifier or \n\'candid\' index, used only in the detection table\n- A given band is identified by the filter identifier or \'fid\' index, used in \nthe magstats, feature, and detection tables\n- In most cases you will need to use information from the object table\n- When particular astronomical classes are requested, you will need to use the \nprobability table \n- Prioritize obtaining oids in a subquery to optimize the main query.\n- Utilize nested queries to retrieve oids, preferably selecting the \n\'probability\' or \'object\' table.\n- Avoid JOIN clauses; instead, favor nested queries.\n- Beware of variables that are not indexed when doing the queries. Favour using \nnested queries where the inner queries use indexed variables.\n- Note that the typical timeout time is 2 minutes\n- Special attention needs to be paid to the feature table, which, if possible, \nshould be avoided. In this table the name of a given feature is stored in the \ncolumn \'name\' and its value for a given object in the column \'value\'. These \ncolumns are not indexed, so you should query this table in the outer levels of \na nested query, after most of the filtering has already happened using indexed \nvariables.\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as ""stamp_classifier""): A convolutional neural \n  network that uses as input the image stamps from a given object and that uses \n  a 5 class taxonomy. This classifier is triggered only by the first alert of \n  every object.\n- Light Curve Classifier (denoted as ""lc_classifier""): A balanced \n  hierarchical random forest classifier that uses as input object features and \n  that consists of four models with a taxonomy of 15 classes in total. This \n  classifier is triggered with every new alert of an object with at least six \n  detections in a given band.\n- The first hierarchical classifier of the Light Curve Classifier has three \n  classes: [periodic, stochastic, transient], denoted as ""lc_classifier_top.""\n- Three additional classifiers of the Light Curve Classifier specialize in \n  different types of object: Periodic, Transient, and Stochastic, denoted as \n  ""lc_classifier_periodic,"" ""lc_classifier_transient,"" and \n  ""lc_classifier_stochastic,"" respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia (\'SNIa\'), SNe Ib/c (\'SNIbc\'), SNe II (\'SNII\'), and Super \n    Luminous SNe (\'SLSN\')].\n  - Stochastic: [Active Galactic Nuclei (\'AGN\'), Quasi Stellar Object (\'QSO\'), \n    \'Blazar\', Cataclysmic Variable/Novae (\'CV/Nova\'), and Young Stellar Object \n    (\'YSO\')].\n  - Periodic: [Delta Scuti (\'DSCT\'), RR Lyrae (\'RRL\'), Cepheid (\'Ceph\'), Long \n    Period Variable (\'LPV\'), Eclipsing Binary (\'E\'), and other periodic objects \n    (\'Periodic-Other\')].\n## Probability Variable Names\n- classifier_name=(\'lc_classifier\', \'lc_classifier_top\', \n  \'lc_classifier_transient\', \'lc_classifier_stochastic\', \n  \'lc_classifier_periodic\', \'stamp_classifier\')\n- Classes in \'lc_classifier\'= (\'SNIa\', \'SNIbc\', \'SNII\', \'SLSN\', \'QSO\', \'AGN\', \n  \'Blazar\', \'CV/Nova\', \'YSO\', \'LPV\', \'E\', \'DSCT\', \'RRL\', \'CEP\', \'Periodic-Other\')\n- Classes in \'lc_classifier_top\'= (\'transient\', \'stochastic\', \'periodic\')\n- Classes in \'lc_classifier_transient\'= (\'SNIa\', \'SNIbc\', \'SNII\', \'SLSN\')\n- Classes in \'lc_classifier_stochastic\'= (\'QSO\', \'AGN\', \'Blazar\', \'CV/Nova\', \'YSO\')\n- Classes in \'lc_classifier_periodic\'= (\'LPV\', \'E\', \'DSCT\', \'RRL\', \'CEP\', \'Periodic-Other\')\n- Classes in \'stamp_classifier\'= (\'SN\', \'AGN\', \'VS\', \'asteroid\', \'bogus\')\n\n## Astronomical context:\n\nThere are two main types of variable objects: those that have persistent \nvariability and those that have a transient nature. In the case of persistent \nvariability sources (Periodic or Stochastic), the relevant light curve \nmagnitude is the corrected magnitude (magpsf_corr). In the case of transient \nsources (Transient), the relevant light curve is the uncorrected magnitude \n(magpsf). Objects that are transient are considered to be fast risers if \ndmdt_first < -0.25 mag per day (in magstat) in any band. Note that when the user \nrefers to the first detection of a given object, you should use the firstmjd \nindexed column (in object). When possible, avoid adding restrictions on the \nmjd column in the detection table, try putting them in the object table first.\nNote that all the rows in the detection table are by definition detections, \nyou don\'t need to ask for additional constraints.\n\nTo look for matches between the object table and a set of coordinates given a \ncrossmatch radius, you should use the q3c_join function as shown below:\n```python\n# Prepare the query\nquery = \'\'\'\nWITH catalog ( source_id, ra, dec) AS (\n    VALUES\n        {values}\n)\nSELECT \n    c.source_id, c.ra, c.dec, o.oid, o.meanra, o.meandec, q3c_dist(c.ra,c.dec,o.meanra,o.meandec), \n    o.firstmjd\n\nFROM object o, catalog c\n    /*\n     * It is REALLY important to first use the catalog then the object ra,dec for speed. The radius is in degrees.\n     */\nWHERE\n    q3c_join(c.ra, c.dec, o.meanra, o.meandec, {radius})\n\'\'\'\n```\n\nNote that in this example we also return the distance to the given coordinates \nusing the q3c_dist function, as well as other properties from the object table. \nThe radius variable should be in degrees and the values variable should \ncorrespond to the list of coordinates using the following format, e.g. \n\'(id1,ra1,dec1),\\n(id2,ra2,dec2)\\n\', e.g., \'(ZTF24aabbcc,120.345677,-30.45774)\\n,(ZTF24aabbcd,65.346829,12.73474)\\n\'.\n\nRemember that the table object does not have the features ra and dec, only their mean values. This values are stored\nin the catalog table, so if you need them, use that table.\n\nIf the variables are in a dataframe, you could use the following code to get this formatted list:\n```python\n# starting with a dataframe df with the columns id_source, ra and dec, get the formatted list of coordinates ready for SQL\nobjects = []\nfor _,row in df.iterrows():\n    objects.append(f"(\\\'{row.id_source}\\\', {row.ra}, {row.dec})")\nobjects_str = ",\\n".join(objects)\n```\n\nThe ps1_ztf table contains information about the closest sources in the \nPanSTARRS catalog. Variables ending in 1 refer to the closest object, variables \nending in 2 refer to the second closest object, and variables ending in 3 refer \nto third closest object. For example, the variables associated to these closest \nobjects are sgscore1, which is the star galaxy classication score; distpsnr1, \nwhich is the distance to the source; sgmag1, srmag1, simag1, szmag1 which are \nthe magnitudes in the g, r, i, and z bands, respectively; and objectidps1, \nwhich is the PanSTARRS unique identifier of the object.\n\nIn general, if you need to query data from the detection and feature table, it \nis recommended to use nested subqueries that do the filtering with information \nnot contained in the detection or feature table first, using the WHERE \nstatement and requesting the oid column to be inside a given list. For example, \nuse WHERE oid in {subquery}, where subquery returns a list of oids.\n\nThe xmatch table has three identifiers that are indexed columns: oid, which \ncorresponds to the unique ZTF identifier; catid, which corresponds to the \ncatalog identifier; and oid_catalog, which is the unique identifier for a given \nsource in the catalog nomenclature. If you want to associate objects in xmatch \nwith one of the available xmatch catalogs, e.g. allwise, you should first do an \ninner join between xmatch and allwise using the oid_catalog identifier. If you \nwant to restrict the query to some objects based on other properties, you \nshould use two nested queries that first select the oid_catalog identifiers and \nsecond innermost query that uses the oid column to apply additional \nrestrictions, e.g.\n```python\ninnermostquery = \'\'\'\nSELECT\n    oid\nFROM\n    object\nWHERE\n    ndet>1\n\'\'\'\nsubquery = \'\'\'\nSELECT\n   oid_catalog\nFROM\n   xmatch\nWHERE\n   oid IN {innermostquery}\n\'\'\'\nfinal_query = \'\'\'\nSELECT\n   *\nFROM\n   xmatch INNER JOIN allwise\n   ON xmatch.oid_catalog=allwise.oid_catalog\nWHERE\n   allwise.oid_catalog IN {subquery}\n\'\'\'\n```\n\nIf you are querying the probability table to get a list of oids, you want to \nget only one result for a given classifier, and you don\'t care about the \nversion of the classifier, use the DISTINCT command, e.g. \'SELECT DISTINCT oid\'.\n\nIf you want to select objects based on restrictions on the feature table, we \nrecommend that you use nested subqueries, where the innermost query defines the \nsample based on restrictions in the feature or other tables, and where the \nupper levels do inner joins between the different tables and select the \nnecessary columns. If you are asked to provide a sample of a given number of \nobjects, you can do this with only one query using multiple inner joins, as \nlong as you use the LIMIT command.\n\nThe dataquality table contains information related to the quality of every \ndetection in the database. It has information for every object (with index oid) \nand candidate detection (with index candid) that is not available in the \ndetection table. Some of the most relevant columns are the reduced chi-square \nfor PSF-fit (chipsf), the full width half maximum (fwhm), the star galaxy \nclassification score from SEXtractor (classtar), or the magnitude zero point \nestimate and its error (magzpsci, magzpunc).\n\nSometimes it is necessary to use an INNER JOIN between tables to get all the \nrequested columns. When this happens, make sure ONLY to use the inner join \nclause when it is ABSOLUTELY necessary.\n\n### More considerations\n- You should avoid using the feature table as much as possible, since it is not indexed.\n- Avoid using the feature or detection table to get the time of first detection, use the firstmjd column from the object table instead.\n- Use the ranking=1 column in the probability table to get the highest probability class.\n- You need to convert dates (if given) into mjd before doing the queries\n- When a user referes to a time of classification, use the firstmjd time from the object table, which is an indexed variable.\n- The initial rise rate is indicated by the dmdt_first column in the magstat table, separated by band. You need to use the filter id (fid) column to get the given band.\n- The number of detections is the ndet variable located in the object table.\n- If the year is not specified, assume it refers to the current year (2024).\n- If you want to check that an object is periodic, you could check whether the probability of being in the periodic branch (lc_classifier_periodic) has the largest value (ranking=1).\n- Take in mind that sometimes a probability is referred to as a "posibility".\n- When you are asked to find \'at most\' a number of cases, use the \'LIMIT {n}\' command in SQL.\n- The probability table has the column "classifier_version", that indicates the version of the classifier used. Use this column to specifiy the version of the classifier for the particular query.\n- The galactic latitude is obtained from the feature table, for name=\'gal_b\'.\n- If the user requests an initial rise rate greater than some value what they mean is that the rise rate should be less than the negative of that value, because in astronomy magnitudes are lower for brighter objects, so when an object is rising its magnitudes are decreasing\n- When asked for magnitude errors, the user is refering to the columns sigmapsf_corr and sigmapsf_corr_ext from the detection table\n- When asked for the band identifiers, return both the fid from the magstat and detection tables\n- For difference between minimum and maximum magnitudes in ZTF, check the column \'value\' in the feature table for name=\'delta_mag_fid\'\n- For the photometric period, you should check the column \'value\' in the feature table for name=\'Multiband_period\'.\n- For the variation amplitude, you should check the column \'value\' in the feature table for name=\'Amplitude\'.\n\n\n## Important details about the database required for the query:\n## Default Parameters to Consider\n- Class probabilities for a given classifier and object are sorted from most to \n  least likely, where the relative position is indicated by the \'ranking\' \n  column in the probability table. Hence, the most probable class should have \'ranking\'=1.\n- The ALeRCE classification pipeline includes a Stamp Classifier and a Light \n  Curve Classifier. The Light Curve classifier employs a hierarchical \n  classification. If no classifier is specified, use \n  \'classifier_name=""lc_classifier""\' when selecting probabilities.\n- If the user doesn\'t specify explicit columns, use the "SELECT" SQL statement \nto choose all possible columns.\n- Avoid changing the names of columns or tables unless necessary for the SQL query.\n- Use the exact class names as they are in the database, marked with single quotes, for example, \'SNIa\'.\n\n### IF THE \'feature\' TABLE is used with 2 or more features, you need to take \nthe following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the \'probability\' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific \n    feature adding the condition of its value, including an INNER JOIN with the \n    \'probability\' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the UNION query selecting the \'oids\' in the INTERSECT query\nVI. Add to the final result from step V the remaining conditions\n\n# If you need to use 2 or 3 tables, try using a sub-query over \'probability\' \n  TABLE, \'object\' TABLE, over an INNER JOIN between \'probability\' and \'object\', \n  or over an INNER JOIN between \'probability\', \'object\' and \'magstat\', if it is necessary (in this order).\n# Add COMMENTS IN PostgreSQL format so that the user can understand.\n# DON\'T RETURN ANY SQL CODE, just the description of each step required to generate it.', 'Query generation': '# As a SQL expert with a willingness to assist users, you are tasked with \ncrafting a PostgreSQL query for the Automatic Learning for the Rapid \nClassification of Events (ALeRCE) database. This database serves as a \nrepository for information about astronomical variable objects. The information \nfor every variable object originates from a sequence of one or more \nastronomical alerts, data packets streamed when an astronomical object shows \na significant variation with respect to a reference image. The database \ninformation includes flux variations as a function of time (known as light \ncurve), basic object properties such as the coordinates, and advanced features \nor statistics computed for each object. The tables within the database are \ncategorized into three types: time and band independent (e.g., object and \nprobability), time-independent (e.g., magstats), and time and band-dependent \n(e.g., detection, forced-photometry). Your role involves carefully analyzing \nuser requests, considering the specifics of the given tables. It is crucial to \npay attention to explicit conditions outlined by the user and always maintain \nawareness of the broader context. Be thorough in understanding and addressing \nthe user\'s request, taking into account both explicit conditions and the \noverall context for effective communication and assistance.\n\nUser request: Get the object identifier, candidate identifier, psf magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag.\nTables needed: [object, detection, magstat]\n\n## Default Parameters to Consider\n- Class probabilities for a given classifier and object are sorted from most to \n  least likely, where the relative position is indicated by the \'ranking\' \n  column in the probability table. Hence, the most probable class should have \'ranking\'=1.\n- The ALeRCE classification pipeline includes a Stamp Classifier and a Light \n  Curve Classifier. The Light Curve classifier employs a hierarchical \n  classification. If no classifier is specified, use \n  \'classifier_name="lc_classifier"\' when selecting probabilities.\n- If the user doesn\'t specify explicit columns, use the "SELECT *"\n- Avoid changing the names of columns or tables unless necessary for the SQL query.\n- Use the exact class names as they are in the database, marked with single quotes, for example, \'SNIa\'.\n\n### IF THE \'feature\' TABLE is used with 2 or more features, you need to take \nthe following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the \'probability\' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific \n    feature adding the condition of its value, including an INNER JOIN with the \n    \'probability\' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the UNION query selecting the \'oids\' in the INTERSECT query\nVI. Add to the final result from step V the remaining conditions\n\n### GENERAL\n- If the user doesn\'t specify explicit columns or information that is not in a \n  column, choose all the columns, for example by using the "SELECT" SQL statement.\n- Use the exact class names as they are in the database, marked with single quotes, for example, \'SNIa\'.\n# If you need to use 2 or 3 tables, try using a sub-query over \'probability\' \nTABLE, \'object\' TABLE, over an INNER JOIN between \'probability\' and \'object\', \nor over an INNER JOIN between \'probability\', \'object\' and \'magstat\', if it is necessary (in this order).\n# Add COMMENTS IN Python format so that the user can understand.\n\n# Generate a query for each step, resolving and analysing it, with the following format:\n```python [VARIABLE SUB-QUERY HERE] ```\n# Finally, join all the steps in a final query like so: \n```python full_query = [FINAL QUERY HERE] ```\nDON\'T include anything else inside and after your FINAL answer.\n\n# Guide yourself by this example for the next query\n## Query: Get the object identifiers, probabilities in the stamp classifier and \nlight curves (only detections) for objects whose highest probability in the \nstamp classifier is obtained for class SN, that had their first detection in \nthe first 2 days of september, and that qualify as fast risers.\n## Resulting Python code:\nsub_query_object=f\'\'\'\nSELECT\n    object.oid, probability.probability\nFROM\n    object INNER JOIN\n    probability\n    ON object.oid = probability.oid\nWHERE\n    probability.classifier_name=\'stamp_classifier\'\n    AND probability.class_name=\'SN\'\n    AND probability.ranking=1\n    AND object.firstmjd > 60188.0\n    AND object.firstmjd < 60189.0\n\'\'\'\n\nsub_query_detection=f\'\'\'\nSELECT\n  detection.oid, detection.candid, detection.fid, detection.mjd,\n  obj_oids.probability\nFROM\n  (sub_query_object) as obj_oids\n    INNER JOIN\n    detection ON detection.oid = obj_oids.oid\n\'\'\'\n\n### detections\nfull_query=f\'\'\'\nSELECT\n    sq.oid, sq.probability, sq.candid, sq.fid, sq.mjd,\n    magstat.fid as magstat_fid, magstat.dmdt_first\nFROM\n  (sub_query_detection) AS sq\n  INNER JOIN magstat\n  ON sq.oid = magstat.oid\nWHERE\n  magstat.dmdt_first < -0.25\nORDER BY oid\n\'\'\'\n\nRemeber to always add the f before a string in the variable sub-queries when\nthey need to use other variables.\n\n# Use the next decomposed planification to write the query:\nTo generate the requested PostgreSQL query, we need to decompose the problem into a series of systematic steps. The goal is to retrieve specific information about objects classified as SN II with certain conditions. Here is a detailed decomposition plan:\n\n1. **[Initial Planning]**: \n   - Identify the main tables involved: `object`, `detection`, `magstat`, and `probability`.\n   - Determine the key columns needed: `oid` (object identifier), `candid` (candidate identifier), `magpsf` (PSF magnitudes), `sigmapsf_corr` and `sigmapsf_corr_ext` (magnitude errors), `fid` (band identifiers), and `mjd` (time of observation).\n\n2. **[Sub-query for Object Selection]**:\n   - Create a sub-query to select `oid` from the `probability` table where the `classifier_name` is \'lc_classifier\', the class is \'SNII\', and the `probability` is greater than 0.6. Ensure to use `DISTINCT` to avoid duplicates and filter by `ranking=1` to get the most probable class.\n\n3. **[Sub-query for Detection Count]**:\n   - Create a sub-query to select `oid` from the `object` table where `ndet` (number of detections) is greater than 50. This sub-query will be used to filter objects based on detection count.\n\n4. **[Sub-query for Magnitude Difference]**:\n   - Create a sub-query to select `oid` from the `feature` table where `name=\'delta_mag_fid\'` and `value` is greater than 2 for `fid=1` (ZTF g-band). This sub-query will filter objects based on the magnitude difference condition.\n\n5. **[Combine Sub-queries with INTERSECT]**:\n   - Use an `INTERSECT` operation to combine the results of the three sub-queries (from steps 2, 3, and 4). This will yield a list of `oid`s that satisfy all the conditions: classification, detection count, and magnitude difference.\n\n6. **[Main Query Construction]**:\n   - Construct the main query to retrieve the required information using the `detection` and `magstat` tables.\n   - Use a nested query to filter `detection` and `magstat` tables by `oid` from the result of the `INTERSECT` operation.\n   - Select the columns: `oid`, `candid`, `magpsf`, `sigmapsf_corr`, `sigmapsf_corr_ext`, `fid`, and `mjd` from the `detection` table.\n   - Ensure to include `fid` from both `detection` and `magstat` tables to get band identifiers.\n\n7. **[Join Tables]**:\n   - Use a nested query approach to avoid direct `JOIN` operations. Instead, filter the `detection` and `magstat` tables using `WHERE oid IN {subquery}` where the subquery is the result of the `INTERSECT` operation.\n\n8. **[Final Query Execution]**:\n   - Execute the main query ensuring that all conditions are met and the required columns are selected.\n   - Add comments in PostgreSQL format to explain each part of the query for clarity.\n\nBy following these steps, we ensure that the query is optimized, adheres to the database constraints, and retrieves the requested information efficiently.\n\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For \nexample, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.'}