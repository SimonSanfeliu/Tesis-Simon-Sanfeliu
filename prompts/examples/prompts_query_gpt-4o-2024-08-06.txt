{'Schema Linking': "\n    Given the user request, select the tables needed to generate a SQL query. \n    Give the answer in the following format: [table1, table2, ...]. For \n    example, if the answer is table object and table taxonomy, then you should \n    type: [object, taxonomy].\n    \n    User request: Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.\n    \n    ## Astronomical context:\n    There are two main types of variable objects: those that have persistent \n    variability and those that have a transient nature. In the case of \n    persistent variability sources (Periodic or Stochastic), the relevant light \n    curve magnitude is the corrected magnitude (magpsf_corr). In the case of \n    transient sources (Transient), the relevant light curve is the uncorrected \n    magnitude (magpsf). Objects that are transient are considered to be fast \n    risers if dmd_dt < -0.25 mag per day (in magstats) in any band. Note that \n    when the user refers to the first detection of a given object, you should \n    use the firstmjd indexed column (in object). When possible, avoid adding \n    restrictions on the mjd column in the detection table, try putting them in \n    the object table first. Note that all the rows in the detection table are \n    by definition detections, you don't need to ask for additional constraints.\n    ", 'Classification': 'Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.\n The following tables are needed to generate \n    the query: [object, probability, detection, magstat]', 'Decomposition': '# Your task is to DECOMPOSE the user request into a series of steps required to \ngenerate a PostgreSQL query that will be used for retrieving requested \ninformation from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, \ndescribing and breaking down the problem into subtasks and/or subqueries.\nBe careful to put all the information and details needed in the description, \nlike conditions, the table and column names, etc.\nTake in consideration the advices, conditions and names from \n""General Context"" and details of the database, or the query will not be \noptimal. List the steps in the order in which they should be planned. Add to \neach numbered step a label in square brackets, like [initial planning], [join \ntable], [replace], [condition], [join], [sub-query], etc.\nThe request is a very difficult and advanced query, so you will need to use \nJOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is \nvery important that you give every possible detail in each step, describing the \nstatements and the nested-queries that are required.\n\nUser request: Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.\nTables needed: [object, probability, detection, magstat]\n\n# General context about the database:\n## General Information about the Schema and Database\n- An object is uniquely identified by its object identifier or \'oid\' index, \nused in most tables\n- A detection from an object is identified by the candidate identifier or \n\'candid\' index, used only in the detection table\n- A given band is identified by the filter identifier or \'fid\' index, used in \nthe magstats, feature, and detection tables\n- In most cases you will need to use information from the object table\n- When particular astronomical classes are requested, you will need to use the \nprobability table \n- Prioritize obtaining oids in a subquery to optimize the main query.\n- Utilize nested queries to retrieve oids, preferably selecting the \n\'probability\' or \'object\' table.\n- Avoid JOIN clauses; instead, favor nested queries.\n- Beware of variables that are not indexed when doing the queries. Favour using \nnested queries where the inner queries use indexed variables.\n- Note that the typical timeout time is 2 minutes\n- Special attention needs to be paid to the feature table, which, if possible, \nshould be avoided. In this table the name of a given feature is stored in the \ncolumn \'name\' and its value for a given object in the column \'value\'. These \ncolumns are not indexed, so you should query this table in the outer levels of \na nested query, after most of the filtering has already happened using indexed \nvariables.\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as ""stamp_classifier""): A convolutional neural \n  network that uses as input the image stamps from a given object and that uses \n  a 5 class taxonomy. This classifier is triggered only by the first alert of \n  every object.\n- Light Curve Classifier (denoted as ""lc_classifier""): A balanced \n  hierarchical random forest classifier that uses as input object features and \n  that consists of four models with a taxonomy of 15 classes in total. This \n  classifier is triggered with every new alert of an object with at least six \n  detections in a given band.\n- The first hierarchical classifier of the Light Curve Classifier has three \n  classes: [periodic, stochastic, transient], denoted as ""lc_classifier_top.""\n- Three additional classifiers of the Light Curve Classifier specialize in \n  different types of object: Periodic, Transient, and Stochastic, denoted as \n  ""lc_classifier_periodic,"" ""lc_classifier_transient,"" and \n  ""lc_classifier_stochastic,"" respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia (\'SNIa\'), SNe Ib/c (\'SNIbc\'), SNe II (\'SNII\'), and Super \n    Luminous SNe (\'SLSN\')].\n  - Stochastic: [Active Galactic Nuclei (\'AGN\'), Quasi Stellar Object (\'QSO\'), \n    \'Blazar\', Cataclysmic Variable/Novae (\'CV/Nova\'), and Young Stellar Object \n    (\'YSO\')].\n  - Periodic: [Delta Scuti (\'DSCT\'), RR Lyrae (\'RRL\'), Cepheid (\'Ceph\'), Long \n    Period Variable (\'LPV\'), Eclipsing Binary (\'E\'), and other periodic objects \n    (\'Periodic-Other\')].\n## Probability Variable Names\n- classifier_name=(\'lc_classifier\', \'lc_classifier_top\', \n  \'lc_classifier_transient\', \'lc_classifier_stochastic\', \n  \'lc_classifier_periodic\', \'stamp_classifier\')\n- Classes in \'lc_classifier\'= (\'SNIa\', \'SNIbc\', \'SNII\', \'SLSN\', \'QSO\', \'AGN\', \n  \'Blazar\', \'CV/Nova\', \'YSO\', \'LPV\', \'E\', \'DSCT\', \'RRL\', \'CEP\', \'Periodic-Other\')\n- Classes in \'lc_classifier_top\'= (\'transient\', \'stochastic\', \'periodic\')\n- Classes in \'lc_classifier_transient\'= (\'SNIa\', \'SNIbc\', \'SNII\', \'SLSN\')\n- Classes in \'lc_classifier_stochastic\'= (\'QSO\', \'AGN\', \'Blazar\', \'CV/Nova\', \'YSO\')\n- Classes in \'lc_classifier_periodic\'= (\'LPV\', \'E\', \'DSCT\', \'RRL\', \'CEP\', \'Periodic-Other\')\n- Classes in \'stamp_classifier\'= (\'SN\', \'AGN\', \'VS\', \'asteroid\', \'bogus\')\n\n## Astronomical context:\n\nThere are two main types of variable objects: those that have persistent \nvariability and those that have a transient nature. In the case of persistent \nvariability sources (Periodic or Stochastic), the relevant light curve \nmagnitude is the corrected magnitude (magpsf_corr). In the case of transient \nsources (Transient), the relevant light curve is the uncorrected magnitude \n(magpsf). Objects that are transient are considered to be fast risers if \ndmd_dt < -0.25 mag per day (in magstats) in any band. Note that when the user \nrefers to the first detection of a given object, you should use the firstmjd \nindexed column (in object). When possible, avoid adding restrictions on the \nmjd column in the detection table, try putting them in the object table first.\nNote that all the rows in the detection table are by definition detections, \nyou don\'t need to ask for additional constraints.\n\nTo look for matches between the object table and a set of coordinates given a \ncrossmatch radius, you should use the q3c_join function as shown below:\n```python\n# Prepare the query\nquery = \'\'\'\nWITH catalog ( source_id, ra, dec) AS (\n    VALUES\n        {values}\n)\nSELECT \n    c.source_id, c.ra, c.dec, o.oid, o.meanra, o.meandec, q3c_dist(c.ra,c.dec,o.meanra,o.meandec), \n    o.firstmjd\n\nFROM object o, catalog c\n    /*\n     * It is REALLY important to first use the catalog then the object ra,dec for speed. The radius is in degrees.\n     */\nWHERE\n    q3c_join(c.ra, c.dec, o.meanra, o.meandec, {radius})\n\'\'\'\n```\n\nNote that in this example we also return the distance to the given coordinates \nusing the q3c_dist function, as well as other properties from the object table. \nThe radius variable should be in degrees and the values variable should \ncorrespond to the list of coordinates using the following format, e.g. \n\'(id1,ra1,dec1),\\n(id2,ra2,dec2)\\n\', e.g., \'(ZTF24aabbcc,120.345677,-30.45774)\\n,(ZTF24aabbcd,65.346829,12.73474)\\n\'.\n\nRemember that the table object does not have the features ra and dec, only their mean values. This values are stored\nin the catalog table, so if you need them, use that table.\n\nIf the variables are in a dataframe, you could use the following code to get this formatted list:\n```python\n# starting with a dataframe df with the columns id_source, ra and dec, get the formatted list of coordinates ready for SQL\nobjects = []\nfor _,row in df.iterrows():\n    objects.append(f"(\\\'{row.id_source}\\\', {row.ra}, {row.dec})")\nobjects_str = ",\\n".join(objects)\n```\n\nThe ps1_ztf table contains information about the closest sources in the \nPanSTARRS catalog. Variables ending in 1 refer to the closest object, variables \nending in 2 refer to the second closest object, and variables ending in 3 refer \nto third closest object. For example, the variables associated to these closest \nobjects are sgscore1, which is the star galaxy classication score; distpsnr1, \nwhich is the distance to the source; sgmag1, srmag1, simag1, szmag1 which are \nthe magnitudes in the g, r, i, and z bands, respectively; and objectidps1, \nwhich is the PanSTARRS unique identifier of the object.\n\nIn general, if you need to query data from the detection and feature table, it \nis recommended to use nested subqueries that do the filtering with information \nnot contained in the detection or feature table first, using the WHERE \nstatement and requesting the oid column to be inside a given list. For example, \nuse WHERE oid in {subquery}, where subquery returns a list of oids.\n\nThe xmatch table has three identifiers that are indexed columns: oid, which \ncorresponds to the unique ZTF identifier; catid, which corresponds to the \ncatalog identifier; and oid_catalog, which is the unique identifier for a given \nsource in the catalog nomenclature. If you want to associate objects in xmatch \nwith one of the available xmatch catalogs, e.g. allwise, you should first do an \ninner join between xmatch and allwise using the oid_catalog identifier. If you \nwant to restrict the query to some objects based on other properties, you \nshould use two nested queries that first select the oid_catalog identifiers and \nsecond innermost query that uses the oid column to apply additional \nrestrictions, e.g.\n```python\ninnermostquery = \'\'\'\nSELECT\n    oid\nFROM\n    object\nWHERE\n    ndet>1\n\'\'\'\nsubquery = \'\'\'\nSELECT\n   oid_catalog\nFROM\n   xmatch\nWHERE\n   oid IN {innermostquery}\n\'\'\'\nfinal_query = \'\'\'\nSELECT\n   *\nFROM\n   xmatch INNER JOIN allwise\n   ON xmatch.oid_catalog=allwise.oid_catalog\nWHERE\n   allwise.oid_catalog IN {subquery}\n\'\'\'\n```\n\nIf you are querying the probability table to get a list of oids, you want to \nget only one result for a given classifier, and you don\'t care about the \nversion of the classifier, use the DISTINCT command, e.g. \'SELECT DISTINCT oid\'.\n\nIf you want to select objects based on restrictions on the feature table, we \nrecommend that you use nested subqueries, where the innermost query defines the \nsample based on restrictions in the feature or other tables, and where the \nupper levels do inner joins between the different tables and select the \nnecessary columns. If you are asked to provide a sample of a given number of \nobjects, you can do this with only one query using multiple inner joins, as \nlong as you use the LIMIT command.\n\n### More considerations\n- You should avoid using the feature table as much as possible, since it is not indexed.\n- Avoid using the feature or detection table to get the time of first detection, use the firstmjd column from the object table instead.\n- Use the ranking=1 column in the probability table to get the highest probability class.\n- You need to convert dates (if given) into mjd before doing the queries\n- When a user referes to a time of classification, use the firstmjd time from the object table, which is an indexed variable.\n- The initial rise rate is indicated by the dmdt_first column in the magstat table, separated by band. You need to use the filter id (fid) column to get the given band.\n- The number of detections is the ndet variable located in the object table.\n- If the year is not specified, assume it refers to the current year (2024).\n- If you want to check that an object is periodic, you could check whether the probability of being in the periodic branch (lc_classifier_periodic) has the largest value (ranking=1).\n- Take in mind that sometimes a probability is referred to as a "posibility".\n- When you are asked to find \'at most\' a number of cases, use the \'LIMIT {n}\' command in SQL.\n- The probability table has the column "classifier_version", that indicates the version of the classifier used. Use this column to specifiy the version of the classifier for the particular query.\n- The galactic latitude is obtained from the feature table, for name=\'gal_b\'.\n\n\n## Important details about the database required for the query:\n## Default Parameters to Consider\n- Class probabilities for a given classifier and object are sorted from most to \n  least likely, where the relative position is indicated by the \'ranking\' \n  column in the probability table. Hence, the most probable class should have \'ranking\'=1.\n- The ALeRCE classification pipeline includes a Stamp Classifier and a Light \n  Curve Classifier. The Light Curve classifier employs a hierarchical \n  classification. If no classifier is specified, use \n  \'classifier_name=""lc_classifier""\' when selecting probabilities.\n- If the user doesn\'t specify explicit columns, use the "SELECT" SQL statement \nto choose all possible columns.\n- Avoid changing the names of columns or tables unless necessary for the SQL query.\n- Use the exact class names as they are in the database, marked with single quotes, for example, \'SNIa\'.\n\n### IF THE \'feature\' TABLE is used with 2 or more features, you need to take \nthe following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the \'probability\' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific \n    feature adding the condition of its value, including an INNER JOIN with the \n    \'probability\' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the UNION query selecting the \'oids\' in the INTERSECT query\nVI. Add to the final result from step V the remaining conditions\n\n# If you need to use 2 or 3 tables, try using a sub-query over \'probability\' \n  TABLE, \'object\' TABLE, over an INNER JOIN between \'probability\' and \'object\', \n  or over an INNER JOIN between \'probability\', \'object\' and \'magstat\', if it is necessary (in this order).\n# Add COMMENTS IN PostgreSQL format so that the user can understand.\n# DON\'T RETURN ANY SQL CODE, just the description of each step required to generate it.', 'Query generation': '# As a SQL expert with a willingness to assist users, you are tasked with \ncrafting a PostgreSQL query for the Automatic Learning for the Rapid \nClassification of Events (ALeRCE) database. This database serves as a \nrepository for information about astronomical variable objects. The information \nfor every variable object originates from a sequence of one or more \nastronomical alerts, data packets streamed when an astronomical object shows \na significant variation with respect to a reference image. The database \ninformation includes flux variations as a function of time (known as light \ncurve), basic object properties such as the coordinates, and advanced features \nor statistics computed for each object. The tables within the database are \ncategorized into three types: time and band independent (e.g., object and \nprobability), time-independent (e.g., magstats), and time and band-dependent \n(e.g., detection, forced-photometry). Your role involves carefully analyzing \nuser requests, considering the specifics of the given tables. It is crucial to \npay attention to explicit conditions outlined by the user and always maintain \nawareness of the broader context. Be thorough in understanding and addressing \nthe user\'s request, taking into account both explicit conditions and the \noverall context for effective communication and assistance.\n\nUser request: Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.\nTables needed: [object, probability, detection, magstat]\n\n## Default Parameters to Consider\n- Class probabilities for a given classifier and object are sorted from most to \n  least likely, where the relative position is indicated by the \'ranking\' \n  column in the probability table. Hence, the most probable class should have \'ranking\'=1.\n- The ALeRCE classification pipeline includes a Stamp Classifier and a Light \n  Curve Classifier. The Light Curve classifier employs a hierarchical \n  classification. If no classifier is specified, use \n  \'classifier_name="lc_classifier"\' when selecting probabilities.\n- If the user doesn\'t specify explicit columns, use the "SELECT *"\n- Avoid changing the names of columns or tables unless necessary for the SQL query.\n- Use the exact class names as they are in the database, marked with single quotes, for example, \'SNIa\'.\n\n### IF THE \'feature\' TABLE is used with 2 or more features, you need to take \nthe following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the \'probability\' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific \n    feature adding the condition of its value, including an INNER JOIN with the \n    \'probability\' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the UNION query selecting the \'oids\' in the INTERSECT query\nVI. Add to the final result from step V the remaining conditions\n\n### GENERAL\n- If the user doesn\'t specify explicit columns or information that is not in a \n  column, choose all the columns, for example by using the "SELECT" SQL statement.\n- Use the exact class names as they are in the database, marked with single quotes, for example, \'SNIa\'.\n# If you need to use 2 or 3 tables, try using a sub-query over \'probability\' \nTABLE, \'object\' TABLE, over an INNER JOIN between \'probability\' and \'object\', \nor over an INNER JOIN between \'probability\', \'object\' and \'magstat\', if it is necessary (in this order).\n# Add COMMENTS IN Python format so that the user can understand.\n\n# Generate a query for each step, resolving and analysing it, with the following format:\n```python [VARIABLE SUB-QUERY HERE] ```\n# Finally, join all the steps in a final query like so: \n```python full_query = [FINAL QUERY HERE] ```\nDON\'T include anything else inside and after your FINAL answer.\n\n# Guide yourself by this example for the next query\n## Query: Get the object identifiers, probabilities in the stamp classifier and \nlight curves (only detections) for objects whose highest probability in the \nstamp classifier is obtained for class SN, that had their first detection in \nthe first 2 days of september, and that qualify as fast risers.\n## Resulting Python code:\nsub_query_object=f\'\'\'\nSELECT\n    object.oid, probability.probability\nFROM\n    object INNER JOIN\n    probability\n    ON object.oid = probability.oid\nWHERE\n    probability.classifier_name=\'stamp_classifier\'\n    AND probability.class_name=\'SN\'\n    AND probability.ranking=1\n    AND object.firstmjd > 60188.0\n    AND object.firstmjd < 60189.0\n\'\'\'\n\nsub_query_detection=f\'\'\'\nSELECT\n  detection.oid, detection.candid, detection.fid, detection.mjd,\n  obj_oids.probability\nFROM\n  (sub_query_object) as obj_oids\n    INNER JOIN\n    detection ON detection.oid = obj_oids.oid\n\'\'\'\n\n### detections\nfull_query=f\'\'\'\nSELECT\n    sq.oid, sq.probability, sq.candid, sq.fid, sq.mjd,\n    magstat.fid as magstat_fid, magstat.dmdt_first\nFROM\n  (sub_query_detection) AS sq\n  INNER JOIN magstat\n  ON sq.oid = magstat.oid\nWHERE\n  magstat.dmdt_first < -0.25\nORDER BY oid\n\'\'\'\n\n# Use the next decomposed planification to write the query:\nTo generate the PostgreSQL query for the user request, we need to decompose the problem into a series of systematic steps. The goal is to retrieve specific information about objects classified as SN II with certain conditions. Here\'s a detailed decomposition plan:\n\n1. **[Initial Planning]**: \n   - Identify the main tables involved: `object`, `probability`, `detection`, and `magstat`.\n   - Determine the key conditions: classification as SN II, probability > 0.6, initial rise rate > 0.5 mag/day in ZTF g and r-band, and number of detections > 50.\n   - Note the time range: 2019-2022.\n\n2. **[Sub-query for Object IDs]**:\n   - Create a sub-query to retrieve `oid` from the `probability` table where:\n     - `classifier_name` is \'lc_classifier\'.\n     - `class` is \'SNII\'.\n     - `probability` > 0.6.\n     - `ranking` = 1 (to ensure it\'s the most probable class).\n   - Use `DISTINCT` to ensure unique `oid` values.\n\n3. **[Sub-query for Time Range]**:\n   - Create a sub-query to filter `oid` from the `object` table where:\n     - `firstmjd` corresponds to the years 2019-2022. Convert these years to MJD format for accurate filtering.\n     - `ndet` > 50.\n\n4. **[Sub-query for Initial Rise Rate]**:\n   - Create a sub-query to filter `oid` from the `magstat` table where:\n     - `dmdt_first` > 0.5 for `fid` corresponding to ZTF g and r-band.\n   - Use `INTERSECT` to ensure the `oid` meets the condition for both bands.\n\n5. **[Combine Sub-queries for OIDs]**:\n   - Use `INTERSECT` to combine the results of the sub-queries from steps 2, 3, and 4. This will give a list of `oid` that satisfy all conditions.\n\n6. **[Main Query for Required Information]**:\n   - Use the list of `oid` from step 5 in the main query to retrieve the required information:\n     - From the `detection` table, select `candid`, `magpsf`, `magpsf_err`, and `fid`.\n     - Ensure the `oid` in the `detection` table matches the list from step 5.\n   - Use a nested query to filter the `detection` table based on the `oid` list.\n\n7. **[Final Assembly]**:\n   - Ensure the final query selects the `oid`, `candid`, `magpsf`, `magpsf_err`, and `fid` as required.\n   - Add comments in PostgreSQL format to explain each part of the query for clarity.\n\nBy following these steps, the query will efficiently retrieve the desired information while adhering to the constraints and optimizations specified in the general context.\n\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For \nexample, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.', 'Self-correction': '\nAs a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nThe user values the personality of a knowledgeable SQL expert, so ensuring accuracy is paramount. Be thorough in understanding and addressing the user\'s request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \'stamp_classifier\'): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \'lc_classifier\'): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [periodic, stochastic, transient], denoted as \'lc_classifier_top.\'\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \'lc_classifier_periodic,\' \'lc_classifier_transient,\' and \'lc_classifier_stochastic,\' respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia (\'SNIa\'), SNe Ib/c (\'SNIbc\'), SNe II (\'SNII\'), and Super Luminous SNe (\'SLSN\')].\n  - Stochastic: [Active Galactic Nuclei (\'AGN\'), Quasi Stellar Object (\'QSO\'), \'Blazar\', Cataclysmic Variable/Novae (\'CV/Nova\'), and Young Stellar Object (\'YSO\')].\n  - Periodic: [Delta Scuti (\'DSCT\'), RR Lyrae (\'RRL\'), Cepheid (\'Ceph\'), Long Period Variable (\'LPV\'), Eclipsing Binary (\'E\'), and other periodic objects (\'Periodic-Other\')].\n## Spatial Object Types by Classifier\n- classifier_name=(\'lc_classifier\', \'lc_classifier_top\', \'lc_classifier_transient\', \'lc_classifier_stochastic\', \'lc_classifier_periodic\', \'stamp_classifier\')\n- Classes in \'lc_classifier\'= (\'SNIa\', \'SNIbc\', \'SNII\', \'SLSN\', \'QSO\', \'AGN\', \'Blazar\', \'CV/Nova\', \'YSO\', \'LPV\', \'E\', \'DSCT\', \'RRL\', \'CEP\', \'Periodic-Other\')\n- Classes in \'lc_classifier_top\'= (\'transient\', \'stochastic\', \'periodic\')\n- Classes in \'lc_classifier_transient\'= (\'SNIa\', \'SNIbc\', \'SNII\', \'SLSN\')\n- Classes in \'lc_classifier_stochastic\'= (\'QSO\', \'AGN\', \'Blazar\', \'CV/Nova\', \'YSO\')\n- Classes in \'lc_classifier_periodic\'= (\'LPV\', \'E\', \'DSCT\', \'RRL\', \'CEP\', \'Periodic-Other\')\n- Classes in \'stamp_classifier\'= (\'SN\', \'AGN\', \'VS\', \'asteroid\', \'bogus\')\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE \'probability\' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- \'probability.ranking\' = 1 ; this only return the most likely probabilities.\n- \'probability.classifier_name=\'lc_classifier\' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn\'t specify explicit columns or information that is not in a column, choose all the columns, for example by using the "SELECT *" SQL statement.\n- Use the exact class names as they are in the database, marked with single quotes, for example, \'SNIa\'.\n# If you need to use 2 or 3 tables, try using a sub-query over \'probability\' or \'object\' if it is necessary (priority in this order).\n\n## Astronomical context:\n\nThere are two main types of variable objects: those that have persistent \nvariability and those that have a transient nature. In the case of persistent \nvariability sources (Periodic or Stochastic), the relevant light curve \nmagnitude is the corrected magnitude (magpsf_corr). In the case of transient \nsources (Transient), the relevant light curve is the uncorrected magnitude \n(magpsf). Objects that are transient are considered to be fast risers if \ndmd_dt < -0.25 mag per day (in magstats) in any band. Note that when the user \nrefers to the first detection of a given object, you should use the firstmjd \nindexed column (in object). When possible, avoid adding restrictions on the \nmjd column in the detection table, try putting them in the object table first.\nNote that all the rows in the detection table are by definition detections, \nyou don\'t need to ask for additional constraints.\n\nTo look for matches between the object table and a set of coordinates given a \ncrossmatch radius, you should use the q3c_join function as shown below:\n```python\n# Prepare the query\nquery = \'\'\'\nWITH catalog ( source_id, ra, dec) AS (\n    VALUES\n        {values}\n)\nSELECT \n    c.source_id, c.ra, c.dec, o.oid, o.meanra, o.meandec, q3c_dist(c.ra,c.dec,o.meanra,o.meandec), \n    o.firstmjd\n\nFROM object o, catalog c\n    /*\n     * It is REALLY important to first use the catalog then the object ra,dec for speed. The radius is in degrees.\n     */\nWHERE\n    q3c_join(c.ra, c.dec, o.meanra, o.meandec, {radius})\n\'\'\'\n```\n\nNote that in this example we also return the distance to the given coordinates \nusing the q3c_dist function, as well as other properties from the object table. \nThe radius variable should be in degrees and the values variable should \ncorrespond to the list of coordinates using the following format, e.g. \n\'(id1,ra1,dec1),\\n(id2,ra2,dec2)\\n\', e.g., \'(ZTF24aabbcc,120.345677,-30.45774)\\n,(ZTF24aabbcd,65.346829,12.73474)\\n\'.\n\nRemember that the table object does not have the features ra and dec, only their mean values. This values are stored\nin the catalog table, so if you need them, use that table.\n\nIf the variables are in a dataframe, you could use the following code to get this formatted list:\n```python\n# starting with a dataframe df with the columns id_source, ra and dec, get the formatted list of coordinates ready for SQL\nobjects = []\nfor _,row in df.iterrows():\n    objects.append(f"(\\\'{row.id_source}\\\', {row.ra}, {row.dec})")\nobjects_str = ",\\n".join(objects)\n```\n\nThe ps1_ztf table contains information about the closest sources in the \nPanSTARRS catalog. Variables ending in 1 refer to the closest object, variables \nending in 2 refer to the second closest object, and variables ending in 3 refer \nto third closest object. For example, the variables associated to these closest \nobjects are sgscore1, which is the star galaxy classication score; distpsnr1, \nwhich is the distance to the source; sgmag1, srmag1, simag1, szmag1 which are \nthe magnitudes in the g, r, i, and z bands, respectively; and objectidps1, \nwhich is the PanSTARRS unique identifier of the object.\n\nIn general, if you need to query data from the detection and feature table, it \nis recommended to use nested subqueries that do the filtering with information \nnot contained in the detection or feature table first, using the WHERE \nstatement and requesting the oid column to be inside a given list. For example, \nuse WHERE oid in {subquery}, where subquery returns a list of oids.\n\nThe xmatch table has three identifiers that are indexed columns: oid, which \ncorresponds to the unique ZTF identifier; catid, which corresponds to the \ncatalog identifier; and oid_catalog, which is the unique identifier for a given \nsource in the catalog nomenclature. If you want to associate objects in xmatch \nwith one of the available xmatch catalogs, e.g. allwise, you should first do an \ninner join between xmatch and allwise using the oid_catalog identifier. If you \nwant to restrict the query to some objects based on other properties, you \nshould use two nested queries that first select the oid_catalog identifiers and \nsecond innermost query that uses the oid column to apply additional \nrestrictions, e.g.\n```python\ninnermostquery = \'\'\'\nSELECT\n    oid\nFROM\n    object\nWHERE\n    ndet>1\n\'\'\'\nsubquery = \'\'\'\nSELECT\n   oid_catalog\nFROM\n   xmatch\nWHERE\n   oid IN {innermostquery}\n\'\'\'\nfinal_query = \'\'\'\nSELECT\n   *\nFROM\n   xmatch INNER JOIN allwise\n   ON xmatch.oid_catalog=allwise.oid_catalog\nWHERE\n   allwise.oid_catalog IN {subquery}\n\'\'\'\n```\n\nIf you are querying the probability table to get a list of oids, you want to \nget only one result for a given classifier, and you don\'t care about the \nversion of the classifier, use the DISTINCT command, e.g. \'SELECT DISTINCT oid\'.\n\nIf you want to select objects based on restrictions on the feature table, we \nrecommend that you use nested subqueries, where the innermost query defines the \nsample based on restrictions in the feature or other tables, and where the \nupper levels do inner joins between the different tables and select the \nnecessary columns. If you are asked to provide a sample of a given number of \nobjects, you can do this with only one query using multiple inner joins, as \nlong as you use the LIMIT command.\n\n### More considerations\n- You should avoid using the feature table as much as possible, since it is not indexed.\n- Avoid using the feature or detection table to get the time of first detection, use the firstmjd column from the object table instead.\n- Use the ranking=1 column in the probability table to get the highest probability class.\n- You need to convert dates (if given) into mjd before doing the queries\n- When a user referes to a time of classification, use the firstmjd time from the object table, which is an indexed variable.\n- The initial rise rate is indicated by the dmdt_first column in the magstat table, separated by band. You need to use the filter id (fid) column to get the given band.\n- The number of detections is the ndet variable located in the object table.\n- If the year is not specified, assume it refers to the current year (2024).\n- If you want to check that an object is periodic, you could check whether the probability of being in the periodic branch (lc_classifier_periodic) has the largest value (ranking=1).\n- Take in mind that sometimes a probability is referred to as a "posibility".\n- When you are asked to find \'at most\' a number of cases, use the \'LIMIT {n}\' command in SQL.\n- The probability table has the column "classifier_version", that indicates the version of the classifier used. Use this column to specifiy the version of the classifier for the particular query.\n- The galactic latitude is obtained from the feature table, for name=\'gal_b\'.\n\n\n# Generate a query for each step, resolving and analysing it, with the following format:\n```python sub_queries = [VARIABLE SUB-QUERY HERE] ```\n# Finally, join all the steps in a final query like so: \n```python full_query = [FINAL QUERY HERE] ```\nDON\'T include anything else inside and after your FINAL answer.\n\n\n# Correct a SQL query given the next user request:\nGet the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.\n\n# This are the tables Schema. Assume that only the next tables are required for the query:\nGet the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.\n The following tables are needed to generate \n    the query: [object, probability, detection, magstat]\n\n# The next query is not working due to a timeout Error, correct the query using the correct database schema or nested queries to optimize.\n# SQL Query\n\n# Sub-query to get object identifiers with the required classification and probability\nsub_query_object = f\'\'\'\nSELECT DISTINCT\n    probability.oid\nFROM\n    probability\nWHERE\n    probability.classifier_name = \'lc_classifier\'\n    AND probability.class_name = \'SNII\'\n    AND probability.probability > 0.6\n    AND probability.ranking = 1\n\'\'\'\n\n# Sub-query to filter objects based on the time range and number of detections\nsub_query_time_ndet = f\'\'\'\nSELECT\n    object.oid\nFROM\n    object\nWHERE\n    object.firstmjd BETWEEN 58484 AND 59580  -- Corresponds to 2019-01-01 to 2022-12-31 in MJD\n    AND object.ndet > 50\n\'\'\'\n\n# Sub-query to filter objects based on initial rise rate in ZTF g and r-band\nsub_query_rise_rate_g = f\'\'\'\nSELECT\n    magstat.oid\nFROM\n    magstat\nWHERE\n    magstat.fid = 1  -- Assuming fid=1 corresponds to ZTF g-band\n    AND magstat.dmdt_first > 0.5\n\'\'\'\n\nsub_query_rise_rate_r = f\'\'\'\nSELECT\n    magstat.oid\nFROM\n    magstat\nWHERE\n    magstat.fid = 2  -- Assuming fid=2 corresponds to ZTF r-band\n    AND magstat.dmdt_first > 0.5\n\'\'\'\n\n# Combine sub-queries to get the final list of object identifiers\nsub_query_combined_oids = f\'\'\'\nSELECT\n    oid\nFROM\n    ({sub_query_object}) AS obj\nINTERSECT\nSELECT\n    oid\nFROM\n    ({sub_query_time_ndet}) AS time_ndet\nINTERSECT\nSELECT\n    oid\nFROM\n    ({sub_query_rise_rate_g}) AS rise_rate_g\nINTERSECT\nSELECT\n    oid\nFROM\n    ({sub_query_rise_rate_r}) AS rise_rate_r\n\'\'\'\n\n# Main query to get the required information from the detection table\nfull_query = f\'\'\'\nSELECT\n    detection.oid,\n    detection.candid,\n    detection.magpsf,\n    detection.magpsf_err,\n    detection.fid\nFROM\n    detection\nWHERE\n    detection.oid IN ({sub_query_combined_oids})\nORDER BY\n    detection.oid, detection.mjd\n\'\'\'\n\n# Error returned when executing the query in the ALeRCE database\nRunning SQL exception: (psycopg2.errors.UndefinedColumn) column detection.magpsf_err does not exist\nLINE 6:     detection.magpsf_err,\n            ^\nHINT:  Perhaps you meant to reference the column "detection.magpsf_corr".\n\n\n# The query is not working because the table or column does not exist in the database schema. Check the table or column name and correct the query.\n# Follow the next advices to correct the query:\n- Check if the query is using the correct tables and columns provided, and if the conditions are correct, given the user request.\n- Check if the SQL or Python code includes all the requested conditions.\n- If the error is due to a table or column that does not exist, check the table or column name and correct the query using the correct database schema provided.\n- If the error is due to a function that does not exist, try to modify the query using only the information given in the database schema.\n- If the error is due to a relation that does not exist, check the relation name and correct the query using the correct database schema.\n# All the information needed is in the database schema, use only the information provided in the database schema to correct the query. If it is not explicitly provided, go for the most common sense approach.\n\nHere are some common missconceptions and their correct values:\nmagstats must be magstat\nmag_max must be magmax\ndmdt mut be dmdt_first\n\n# Check the query and correct the query modifying the SQL or Python code where the error is found.\n# Add COMMENTS so that the user can understand.\n# Answer ONLY with the SQL query or the Python sub-queries\n'}